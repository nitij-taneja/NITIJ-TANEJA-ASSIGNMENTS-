{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_AkhnAD8hb6d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 1 : What is relationship between polynomial funtions and kernel functions in machine learning algorithms ?\n",
        "\n",
        "Answer :\n",
        "\n",
        "Polynomial functions and kernel functions are both commonly used in machine\n",
        "learning algorithms, but they have different roles.\n",
        "\n",
        "Polynomial functions are a type of function that can be used to fit data by using a polynomial equation to model the relationship between the input and output variables. In the context of machine learning, polynomial functions are often used as basis functions in linear regression models, where they are used to transform the input data into a higher-dimensional space so that linear decision boundaries can be more easily defined.\n",
        "\n",
        "Kernel functions, on the other hand, are used to define similarity measures between pairs of data points in a high-dimensional space. In machine learning, kernel functions are commonly used in kernel methods, such as support vector machines (SVMs) and kernelized ridge regression, to transform the input data into a high-dimensional space where linear decision boundaries can be more easily defined.\n",
        "\n",
        "One type of kernel function that is often used in kernel methods is the polynomial kernel, which computes the similarity between two data points as the dot product of their feature representations raised to a certain power (i.e., a polynomial function). This allows the kernel method to implicitly define nonlinear decision boundaries in the original input space, without the need to explicitly compute the high-dimensional feature space.\n",
        "\n",
        "In summary, while polynomial functions and kernel functions are both used in machine learning algorithms, they serve different purposes. Polynomial functions are used as basis functions in linear regression models, while kernel functions are used to define similarity measures between pairs of data points in a high-dimensional space, often as part of kernel methods."
      ],
      "metadata": {
        "id": "2QNtxLLmiNH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 2 : How can we implement SVM with polynomial kernel in Python using Scikit-learn library?"
      ],
      "metadata": {
        "id": "REK3NC3xiaP3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Generate a random dataset for demonstration purposes\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_classes=2,n_informative=5 ,random_state=42)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create an SVM classifier with a polynomial kernel\n",
        "svm_classifier = svm.SVC(kernel='poly', degree=3)\n",
        "\n",
        "# Fit the classifier to the training data\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels of the test data\n",
        "y_pred = svm_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the classifier's accuracy on the test data\n",
        "accuracy = svm_classifier.score(X_test, y_test)\n",
        "print(\"Testing Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxXEQB_3idBn",
        "outputId": "598c70f1-a753-45fe-a056-3849eaacbda9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Accuracy: 0.895\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "cf = confusion_matrix(y_test,y_pred)\n",
        "sns.heatmap(cf,annot=True,fmt='d')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "NMKfDfXhig5X",
        "outputId": "b557ce9d-33d7-472f-f2f7-4b45b9fb1b2b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 2
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCGW3n8Xikac",
        "outputId": "45c0900f-bdfb-4c17-e975-977f9f15a380"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.87      0.90       112\n",
            "           1       0.85      0.93      0.89        88\n",
            "\n",
            "    accuracy                           0.90       200\n",
            "   macro avg       0.89      0.90      0.89       200\n",
            "weighted avg       0.90      0.90      0.90       200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nPZDE3J9imvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 3 : How does the increasing value of epsilon affect the number of support vectors in SVR?\n",
        "\n",
        "Answer :\n",
        "\n",
        "In Support Vector Regression (SVR), the parameter epsilon controls the width of the epsilon-insensitive tube, which is the region where errors are not penalized. Specifically, any training data point within the epsilon-insensitive tube does not contribute to the loss function.\n",
        "\n",
        "Increasing the value of epsilon can affect the number of support vectors in SVR\n",
        "in a couple of ways:\n",
        "\n",
        "Fewer support vectors: As the value of epsilon increases, the width of the epsilon-insensitive tube also increases. This means that fewer data points will fall outside of the tube and become support vectors. As a result, increasing epsilon tends to reduce the number of support vectors.\n",
        "\n",
        "More support vectors: On the other hand, increasing epsilon can also cause some data points that were previously outside of the tube to move inside the tube and become support vectors. This is because increasing epsilon can make the SVR model more tolerant to errors and allow more data points to be within the tube. In some cases, this can lead to an increase in the number of support vectors.\n",
        "\n",
        "Overall, the effect of increasing epsilon on the number of support vectors in SVR will depend on the specific dataset and the other hyperparameters of the model. In practice, it is often necessary to tune the value of epsilon along with other hyperparameters to achieve the best performance.\n",
        "\n"
      ],
      "metadata": {
        "id": "N_mB5g2XioaJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 4 : How does the choice of kernel function, C parameter, epsilon parameter affect the performance of SVR? Can you explain how each parameter works and provide examples of when you might increase or decrease the value?\n",
        "\n",
        "Answer :\n",
        "\n",
        "The choice of kernel function, C parameter, and epsilon parameter can all have a significant impact on the performance of Support Vector Regression (SVR).\n",
        "\n",
        "Kernel Function: The kernel function determines how the SVR model transforms the input data into a higher-dimensional feature space. Different kernel functions have different properties and are better suited for different types of data.\n",
        "\n",
        "Choosing the right kernel function can greatly improve the performance of the SVR model. It's usually a good idea to try different kernel functions and choose the one that performs the best on the validation set.For example:\n",
        "\n",
        "* Linear kernel: Suitable for linearly separable data and large datasets\n",
        "* Polynomial kernel: Suitable for non-linear data and can capture complex relationships\n",
        "* Radial basis function (RBF) kernel: Suitable for non-linear data and can capture local and global patterns\n",
        "\n",
        "C Parameter: The C parameter controls the trade-off between the complexity of the model and the degree to which deviations larger than epsilon are penalized. A larger C parameter means that the model is more tolerant of errors and may overfit the data, while a smaller C parameter means that the model is less tolerant of errors and may underfit the data. In general:\n",
        "\n",
        "If the training data is noisy or has outliers, a larger C parameter may be needed to allow the model to fit the data better.\n",
        "\n",
        "If the training data is clean or has few outliers, a smaller C parameter may be sufficient to obtain good performance.\n",
        "\n",
        "Epsilon Parameter: The epsilon parameter controls the width of the epsilon-insensitive tube, which is the region where errors are not penalized. A larger epsilon parameter means that the model is more tolerant of errors and may allow more data points to be within the tube, while a smaller epsilon parameter means that the model is less tolerant of errors and may force more data points outside the tube. In general:\n",
        "\n",
        "If the training data is noisy or has many outliers, a larger epsilon parameter may be needed to allow the model to fit the data better.\n",
        "\n",
        "If the training data is clean or has few outliers, a smaller epsilon parameter may be sufficient to obtain good performance.\n",
        "\n",
        "Overall, the choice of kernel function, C parameter, and epsilon parameter should be based on the characteristics of the data and the desired level of complexity of the model. It's often a good idea to try different combinations of hyperparameters and choose the ones that perform the best on the validation set.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aSYvP1Jii0fV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5 : Assignment\n",
        "\n",
        "Import necessary libraries and load the dataset\n",
        "\n",
        "Split the dataset into training and testing set\n",
        "\n",
        "Preprocess the data with any technique of your choice (eg. scaling, normaliazation)\n",
        "\n",
        "Create an instance of SVC Classifer and train it on training data\n",
        "\n",
        "Use trained Classifier to predict labels on testing data\n",
        "\n",
        "Evaluate the performance of classifier using any metric of your choice\n",
        "\n",
        "Tune Hyperparameter of SVC using GridSearchCV or RandomizedSearchCV to imporve the performance\n",
        "\n",
        "Train the tuned classifier for entire dataset\n",
        "\n",
        "Save the trained classifier to a file for future use"
      ],
      "metadata": {
        "id": "LiCjCrH3jT28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import joblib\n",
        "\n",
        "# Load the dataset\n",
        "iris = sns.load_dataset('iris')\n",
        "print(iris.head())\n",
        "print()\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris.drop('species', axis=1), iris['species'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Preprocess the data (scaling in this case)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Create an instance of SVC Classifier and train it on training data\n",
        "svc = SVC()\n",
        "svc.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Use trained Classifier to predict labels on testing data\n",
        "y_pred = svc.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the performance of the classifier using accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print()\n",
        "# Tune Hyperparameters using GridSearchCV\n",
        "param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf', 'poly'], 'gamma': ['scale', 'auto']}\n",
        "grid_search = GridSearchCV(SVC(), param_grid, cv=5)\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "print('Best Params:',grid_search.best_params_)\n",
        "\n",
        "# Train the tuned classifier for the entire dataset\n",
        "tuned_svc = grid_search.best_estimator_\n",
        "tuned_svc.fit(scaler.transform(iris.drop('species', axis=1)), iris['species'])\n",
        "\n",
        "# Save the trained classifier to a file for future use\n",
        "joblib.dump(tuned_svc, 'svm_classifier.joblib')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kktCv9Dbxhjd",
        "outputId": "ff0a4c61-d165-4d60-c24b-fdd34eb534ab"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sepal_length  sepal_width  petal_length  petal_width species\n",
            "0           5.1          3.5           1.4          0.2  setosa\n",
            "1           4.9          3.0           1.4          0.2  setosa\n",
            "2           4.7          3.2           1.3          0.2  setosa\n",
            "3           4.6          3.1           1.5          0.2  setosa\n",
            "4           5.0          3.6           1.4          0.2  setosa\n",
            "\n",
            "Accuracy: 1.00\n",
            "\n",
            "Best Params: {'C': 10, 'gamma': 'scale', 'kernel': 'linear'}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['svm_classifier.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mTI7xsP7yskb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}